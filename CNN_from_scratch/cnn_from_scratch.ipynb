{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "x5KAXj1YqoEy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previous"
      ],
      "metadata": {
        "id": "yQEMk5SAp787"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "02uPA05Npxin"
      },
      "outputs": [],
      "source": [
        "class GradientDescent():\n",
        "\n",
        "\n",
        "    def __init__(self, lr = 1e-3, eps = 1e-4):\n",
        "        self.lr = lr\n",
        "        self.eps = eps\n",
        "        self.delta = 0\n",
        "\n",
        "\n",
        "    def optimize(self, target, gradients):\n",
        "        optimized = []\n",
        "        for t, grad in zip(target, gradients):\n",
        "            optimized.append(t - self.lr * grad)\n",
        "            self.delta += self.lr * np.linalg.norm(grad)\n",
        "        return optimized\n",
        "\n",
        "\n",
        "    def stop(self):\n",
        "        return not(self.delta > 1e-9 or self.delta < self.eps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, inner_ndim):\n",
        "\n",
        "        self.n_input = (input_dim, ) if isinstance(input_dim, int) else tuple(input_dim)\n",
        "        self.input_dim = 1 if isinstance(input_dim, int) else len(self.n_input)\n",
        "        self.n_output = (output_dim, ) if isinstance(output_dim, int) else tuple(output_dim)\n",
        "        self.output_dim = 1 if isinstance(input_dim, int) else len(self.n_output)\n",
        "        self.inner_dim = inner_ndim\n",
        "        self.input = None\n",
        "        self.labels = None\n",
        "\n",
        "\n",
        "\n",
        "    def change_dims(self, x, dim):\n",
        "        return np.reshape(x, x.shape[-dim:]) if x.ndim > dim else (x if x.ndim == dim else np.expand_dims(x, tuple(range(dim - x.ndim))))"
      ],
      "metadata": {
        "id": "P4-baz1mqGLs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax(Node):\n",
        "\n",
        "\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__(n_input, n_input, inner_ndim=2)\n",
        "\n",
        "\n",
        "    def softmax_call(self, x):\n",
        "        self.sm_max_index = np.argmax(np.abs(x), axis=1).reshape(-1, 1)\n",
        "        self.softmax_x_norm = x / np.max(np.abs(x), axis=1).reshape(-1, 1)\n",
        "        exp = np.exp(self.softmax_x_norm)\n",
        "        return exp / exp.sum(axis=1).reshape(-1, 1)\n",
        "\n",
        "\n",
        "    def jacobian(self, x):\n",
        "        rows, classes = self.softmax_x_norm.shape\n",
        "        exp_x = np.exp(self.softmax_x_norm)\n",
        "        exp_sum = exp_x.sum(axis=1)\n",
        "\n",
        "        softmax_jacobian = np.zeros((rows, classes, classes))\n",
        "\n",
        "        for row in range(rows):\n",
        "            exp_x_row = exp_x[row]\n",
        "            exp_sum_row = exp_sum[row]\n",
        "            diag = np.diag([exp_xi / exp_sum_row - (exp_xi / exp_sum_row) ** 2 for exp_xi in exp_x_row])\n",
        "            triag = np.array([[-exp_x_row[i] * exp_x_row[j] / exp_sum_row**2 if i > j else 0 for i in range(classes)] for j in range(classes)])\n",
        "            softmax_jacobian[row] = diag + triag + triag.T\n",
        "\n",
        "        for row in range(x.shape[0]):\n",
        "            max_index = self.sm_max_index[row][0]\n",
        "            x_max = np.abs(x)[row, max_index]\n",
        "            dx_norm_dx = np.diag([1/x_max for _ in range(x.shape[1])])\n",
        "            dx_norm_dx[:, max_index] = np.array([-x_i / x_max**2 for x_i in x[row]])\n",
        "            dx_norm_dx[max_index] = np.zeros(x.shape[1])\n",
        "            softmax_jacobian[row] = softmax_jacobian[row] @ dx_norm_dx\n",
        "\n",
        "        return softmax_jacobian\n",
        "\n",
        "\n",
        "    def forward(self, input, labels = None):\n",
        "        self.input = self.change_dims(input, self.inner_dim)\n",
        "        self.labels = self.change_dims(labels, self.inner_dim)\n",
        "        return self.change_dims(self.softmax_call(self.input), self.output_dim)\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        backprop_pd = self.jacobian(self.input)\n",
        "        self.input = None\n",
        "        self.labels = None\n",
        "        return self.change_dims(backprop_pd, self.input_dim)"
      ],
      "metadata": {
        "id": "bpejKzs4qHRt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU(Node):\n",
        "\n",
        "\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__(n_input, n_input, 2)\n",
        "\n",
        "\n",
        "    def jacobian(self, x):\n",
        "        return np.array([np.diag([1 if x_elem > 0 else 0 for x_elem in x_row]) for x_row in x])\n",
        "\n",
        "\n",
        "    def forward(self, input, labels = None):\n",
        "        self.input = self.change_dims(input, self.inner_dim)\n",
        "        return self.change_dims(np.maximum(self.input, 0), self.output_dim)\n",
        "\n",
        "\n",
        "    def backward(self, input_pd):\n",
        "        input_pd = self.change_dims(input_pd, self.inner_dim)\n",
        "        jacobian = self.jacobian(self.input)\n",
        "        backprop_pd = np.array([jacobian[i] @ input_pd[i] for i in range(jacobian.shape[0])])\n",
        "        return self.change_dims(backprop_pd, self.output_dim)\n",
        "\n",
        "\n",
        "    def optimize_weights(self, optimizer):\n",
        "        pass"
      ],
      "metadata": {
        "id": "a7Xss0Q5qIxV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution(Node):\n",
        "\n",
        "\n",
        "    def __init__(self, input_dim, conv_dim, W = None):\n",
        "        super().__init__(input_dim, (1, input_dim[1] - conv_dim[1] + 1, input_dim[1] - conv_dim[1] + 1), 3)\n",
        "        self.W = np.random.uniform(0.4, 0.6, conv_dim) if W is None else W\n",
        "        self.input_values = None\n",
        "        self.output_values = None\n",
        "        self.labels = None\n",
        "        self.W_pd = None\n",
        "\n",
        "\n",
        "    def convolve(self, T, W, add_padding = False):\n",
        "        T = np.expand_dims(T, axis=0) if T.ndim == 2 else T\n",
        "        W = np.expand_dims(W, axis=0) if W.ndim == 2 else W\n",
        "        output_shape = (1, (T.shape[1] + W.shape[1] - 1), (T.shape[2] + W.shape[2] - 1)) if add_padding else (1, (T.shape[1] - W.shape[1] + 1), (T.shape[2] - W.shape[2] + 1))\n",
        "        T = np.pad(T, pad_width=[(0, 0), (W.shape[1] - 1, W.shape[1] - 1), (W.shape[2] - 1, W.shape[2] - 1)]) if add_padding else T\n",
        "\n",
        "        convolution = np.zeros(output_shape)\n",
        "        for row in range(output_shape[1]):\n",
        "            for col in range(output_shape[2]):\n",
        "                convolution[0, row, col] = np.sum(T[:, row: row + W.shape[1], col: col + W.shape[2]] * W)\n",
        "        return convolution\n",
        "\n",
        "\n",
        "    def forward(self, input, labels = None):\n",
        "        self.input_values = self.change_dims(input, self.inner_dim)\n",
        "        self.output_values = self.convolve(self.input_values, self.W)\n",
        "        return self.change_dims(self.output_values, self.output_dim)\n",
        "\n",
        "\n",
        "    def backward(self, input_pd):\n",
        "        self.W_pd = np.concatenate([self.convolve(self.input_values[i], self.change_dims(input_pd, self.inner_dim)) for i in range(self.n_input[0])], axis=0)\n",
        "        return self.change_dims(np.concatenate([self.convolve(self.change_dims(input_pd, self.inner_dim), self.W[i, ::-1, ::-1], True) for i in range(self.n_input[0])], axis=0), self.output_dim)\n",
        "\n",
        "\n",
        "    def optimize_weights(self, gd):\n",
        "        self.W = gd.optimize([self.W], [self.W_pd])[0]"
      ],
      "metadata": {
        "id": "PO5oeXy1qcpp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayer():\n",
        "\n",
        "    def __init__(self, n_input, n_output):\n",
        "        self.n_input = n_input\n",
        "        self.n_output = n_output\n",
        "        self.W = np.random.randn(n_input, n_output)\n",
        "        self.b = np.zeros(n_output)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.W) + self.b\n",
        "\n",
        "    def backward(self, grad_output, learning_rate):\n",
        "        grad_input = np.dot(grad_output, self.W.T)\n",
        "        grad_weights = np.dot(self.input.T, grad_output)\n",
        "        grad_biases = np.sum(grad_output, axis=0)\n",
        "\n",
        "        self.W -= learning_rate * grad_weights\n",
        "        self.b -= learning_rate * grad_biases\n",
        "\n",
        "        return grad_input"
      ],
      "metadata": {
        "id": "3h7rhGBvudD0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanSquaredError():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true = y_true\n",
        "        loss = np.mean((y_pred - y_true) ** 2)\n",
        "        return loss\n",
        "\n",
        "    def backward(self):\n",
        "        batch_size = self.y_true.shape[0]\n",
        "        grad_input = 2 * (self.y_pred - self.y_true) / batch_size\n",
        "        return grad_input"
      ],
      "metadata": {
        "id": "o5Ls43PN0M3M"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNetwork:\n",
        "\n",
        "    def __init__(self, n_input, n_output, lr):\n",
        "        self.layers = [Convolution((n_output, n_input), (n_input, n_output)), Convolution((n_output, n_input), (n_input, n_output)), FullyConnectedLayer(128, 576), FullyConnectedLayer(n_output, 128), Softmax(n_output), ReLU(n_output), ReLU(n_output)]\n",
        "        self.loss = MeanSquaredError()\n",
        "        self.gd = GradientDescent(lr)\n",
        "\n",
        "\n",
        "    def fit(self, X, y, n_epochs):\n",
        "        n = 0\n",
        "        while True:\n",
        "            loss = 0\n",
        "            for batch in range(X.shape[0]):\n",
        "                state = X[batch]\n",
        "                label = y[batch]\n",
        "\n",
        "                state = self.predict(state)\n",
        "                loss += self.loss.forward(state, label)\n",
        "\n",
        "                upstream = self.loss.backward()\n",
        "                for layer in self.layers[::-1]:\n",
        "                    upstream = layer.backward(upstream)\n",
        "                    layer.optimize_weights(self.gd)\n",
        "            n += 1\n",
        "            print(f\"Epoch {n}, Loss: {loss}\")\n",
        "\n",
        "            if n >= n_epochs or self.gd.stop():\n",
        "                break\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        state = x.copy()\n",
        "        for layer in self.layers:\n",
        "            state = layer.forward(state)\n",
        "        return state"
      ],
      "metadata": {
        "id": "J-HtWfCKqLa8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1"
      ],
      "metadata": {
        "id": "dAm8Wbalqf_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_vec_func(labels):\n",
        "    labels_matrix = np.zeros([len(labels), 10])\n",
        "    labels_matrix[np.arange(len(labels)), labels] = 1\n",
        "    return labels_matrix"
      ],
      "metadata": {
        "id": "P0KuyHW_qhKi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "n_input, n_output = 784, 10\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "y_train_one_hot = label_vec_func(y_train).reshape((y_train.shape[0], 10))"
      ],
      "metadata": {
        "id": "gNmEPXXI0jgk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = ConvolutionalNeuralNetwork(n_input, n_output, 0.5)\n",
        "network.fit(X_train, y_train_one_hot, n_epochs=2)"
      ],
      "metadata": {
        "id": "wBRU1T4r0lx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(X_test, y_test, model):\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total = 0\n",
        "\n",
        "    for input, label in zip(X_test, y_test):\n",
        "        predicts = model.predict(input)\n",
        "        correct_predictions += (np.argmax(predicts, axis=1) == label).sum()\n",
        "        total += len(label)\n",
        "\n",
        "    return correct_predictions / total"
      ],
      "metadata": {
        "id": "9LnMmc3g0u5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_batches = X_test.reshape((X_test.shape[0], -1))\n",
        "y_batches = y_test.reshape((y_test.shape[0],))"
      ],
      "metadata": {
        "id": "xi1UZTVT0zhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {compute_accuracy(X_batches, y_batches, network)}\")"
      ],
      "metadata": {
        "id": "j2r8ahbo00Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2"
      ],
      "metadata": {
        "id": "iwg8W4yM2pP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchNetwork(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=10):\n",
        "        super(TorchNetwork, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3)\n",
        "        self.fc1 = nn.Linear(576, 128)\n",
        "        self.fc2 = nn.Linear(128, out_channels)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-fFHlUi42bq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
        "\n",
        "network = TorchNetwork().to('cpu')\n",
        "loss_function = nn.CrossEntropyLoss().to('cpu')\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(2):\n",
        "    bar = tqdm(trainloader)\n",
        "    total_loss = 0\n",
        "    for i, (inputs, targets) in enumerate(bar):\n",
        "        inputs = inputs.to('cpu')\n",
        "        targets = targets.to('cpu')\n",
        "\n",
        "        outputs = network(inputs)\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        bar.set_description('Epoch: %d/%d | Loss: %.4f' % (epoch + 1, 2, total_loss / (i + 1)))"
      ],
      "metadata": {
        "id": "Q3aC7g1-2xmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    bar = tqdm(testloader)\n",
        "    for data in bar:\n",
        "        inputs, targets = data\n",
        "        outputs = network(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += 1\n",
        "        correct += (predicted == targets).item()\n",
        "        bar.set_description('Accuracy: %.2f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "ByjfQJke25Ls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}